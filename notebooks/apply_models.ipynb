{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:49:40.794414Z",
     "start_time": "2023-10-30T09:49:40.513641Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### read data and conf"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b4dcede99fb2b31"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "json_path = 'data/summarization/text_files'\n",
    "data_file_name = 'txt_dataset_summarizer.json'\n",
    "conf_file_name = 'txt_dataset_summarizer_config.json'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T11:06:49.570053Z",
     "start_time": "2023-10-30T11:06:49.565190Z"
    }
   },
   "id": "3579bbe1db219dd3"
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  word_count  \\\n0  (CNN)A mammoth fire broke out Friday morning i...         143   \n1  Hull, Leicester and Swansea City are following...         147   \n2  Sportsmail have teamed up with Golfbidder to o...         123   \n\n                                              golden  \\\n0  Fire breaks out at the General Electric Applia...   \n1  Hull's chief scout Stan Ternent has watched  M...   \n2  Sportsmail have teamed up with Golfbidder for ...   \n\n                                              notion  \\\n0  A massive fire broke out at the General Electr...   \n1  Hull, Leicester, and Swansea City are interest...   \n2  Sportsmail and Golfbidder have partnered to of...   \n\n                                           grammarly  \\\n0  A massive fire broke out at the General Electr...   \n1  Hull, Leicester, and Swansea City are interest...   \n2  Sportsmail and Golfbidder are running a compet...   \n\n                             current_doc_summarizier  \\\n0  A large fire broke out Friday morning in the G...   \n1  Maciej Rybus, a 25-year-old Polish internation...   \n2  Sportsmail have partnered with Golfbidder to o...   \n\n                           current_update_summarizer  \\\n0  A large fire broke out Friday morning in the G...   \n1  Maciej Rybus, a 25-year-old Polish internation...   \n2  Sportsmail and Golfbidder have teamed up to of...   \n\n                                version_1_summarizer  \\\n0  Title: Fire Breaks Out in Kentucky Industrial ...   \n1  Title: Maciej Rybus Followed by Hull, Leiceste...   \n2  Title: Win a Callaway Golf Prize Bundle Worth ...   \n\n                                version_2_summarizer  \\\n0  Title: Fire Breaks Out in Kentucky Industrial ...   \n1  Title: Maciej Rybus Followed by Hull, Leiceste...   \n2  Title: Win a Callaway Golf Prize Bundle Worth ...   \n\n                                version_3_summarizer  \n0  A fire broke out Friday morning in a Kentucky ...  \n1  Hull, Leicester and Swansea City are intereste...  \n2  One lucky reader has the chance to win a bundl...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>word_count</th>\n      <th>golden</th>\n      <th>notion</th>\n      <th>grammarly</th>\n      <th>current_doc_summarizier</th>\n      <th>current_update_summarizer</th>\n      <th>version_1_summarizer</th>\n      <th>version_2_summarizer</th>\n      <th>version_3_summarizer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(CNN)A mammoth fire broke out Friday morning i...</td>\n      <td>143</td>\n      <td>Fire breaks out at the General Electric Applia...</td>\n      <td>A massive fire broke out at the General Electr...</td>\n      <td>A massive fire broke out at the General Electr...</td>\n      <td>A large fire broke out Friday morning in the G...</td>\n      <td>A large fire broke out Friday morning in the G...</td>\n      <td>Title: Fire Breaks Out in Kentucky Industrial ...</td>\n      <td>Title: Fire Breaks Out in Kentucky Industrial ...</td>\n      <td>A fire broke out Friday morning in a Kentucky ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hull, Leicester and Swansea City are following...</td>\n      <td>147</td>\n      <td>Hull's chief scout Stan Ternent has watched  M...</td>\n      <td>Hull, Leicester, and Swansea City are interest...</td>\n      <td>Hull, Leicester, and Swansea City are interest...</td>\n      <td>Maciej Rybus, a 25-year-old Polish internation...</td>\n      <td>Maciej Rybus, a 25-year-old Polish internation...</td>\n      <td>Title: Maciej Rybus Followed by Hull, Leiceste...</td>\n      <td>Title: Maciej Rybus Followed by Hull, Leiceste...</td>\n      <td>Hull, Leicester and Swansea City are intereste...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sportsmail have teamed up with Golfbidder to o...</td>\n      <td>123</td>\n      <td>Sportsmail have teamed up with Golfbidder for ...</td>\n      <td>Sportsmail and Golfbidder have partnered to of...</td>\n      <td>Sportsmail and Golfbidder are running a compet...</td>\n      <td>Sportsmail have partnered with Golfbidder to o...</td>\n      <td>Sportsmail and Golfbidder have teamed up to of...</td>\n      <td>Title: Win a Callaway Golf Prize Bundle Worth ...</td>\n      <td>Title: Win a Callaway Golf Prize Bundle Worth ...</td>\n      <td>One lucky reader has the chance to win a bundl...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(f'{json_path}/{data_file_name}', orient='index')\n",
    "with open(f'{json_path}/{conf_file_name}') as f:\n",
    "    conf_json = json.load(f)\n",
    "    \n",
    "data.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:44:42.904057Z",
     "start_time": "2023-10-30T12:44:42.889105Z"
    }
   },
   "id": "3070c442a7af432b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building new prompts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "314d671f345a7292"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "azure_openai_key = os.environ.get('AZURE_OPENAI_KEY')\n",
    "azure_openai_endpoint = os.environ.get('AZURE_OPENAI_ENDPOINT')\n",
    "\n",
    "openai.api_key = azure_openai_key\n",
    "openai.api_base = azure_openai_endpoint\n",
    "openai.api_type = \"azure\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:52:21.362543Z",
     "start_time": "2023-10-30T09:52:21.358103Z"
    }
   },
   "id": "d44634371492b68f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class OpenaiCompletionBase:\n",
    "    def __init__(self, model_name=\"text-davinci-003\",\n",
    "                 api_version=\"2023-05-15\", temperature=0.0, max_tokens=200, prompt_template=\"\"):\n",
    "        self.model_name = model_name\n",
    "        self.api_version = api_version\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.prompt_template = prompt_template\n",
    "\n",
    "    def _get_response(self, **input_args):\n",
    "        prompt = self.prompt_template.format(**input_args)\n",
    "        response = openai.Completion.create(\n",
    "            engine=self.model_name,\n",
    "            api_version=self.api_version,\n",
    "            prompt=prompt,\n",
    "            temperature=self.temperature,\n",
    "            max_tokens=self.max_tokens,\n",
    "        )\n",
    "\n",
    "        return response\n",
    "\n",
    "    def call_llm(self, input_text):\n",
    "        input_args = {\"input_text\": input_text}\n",
    "        response = self._get_response(**input_args)\n",
    "        output_text = response[\"choices\"][0][\"text\"].strip()\n",
    "        return output_text\n",
    "\n",
    "    def call_llm_with_res(self, input_text):\n",
    "        input_args = {\"input_text\": input_text}\n",
    "        response = self._get_response(**input_args)\n",
    "        output_text = response[\"choices\"][0][\"text\"].strip()\n",
    "        return output_text, response\n",
    "\n",
    "    def get_config(self):\n",
    "        return self.__dict__\n",
    "\n",
    "\n",
    "class OpenaiCompletionWordLimit(OpenaiCompletionBase):\n",
    "    def __init__(self, model_name=\"text-davinci-003\",\n",
    "                 api_version=\"2023-05-15\", temperature=0.0, max_tokens=200, prompt_template=\"\", max_word_ratio=0.6):\n",
    "        super().__init__(model_name, api_version, temperature, max_tokens, prompt_template)\n",
    "        self.max_word_ratio = max_word_ratio\n",
    "\n",
    "    def call_llm(self, input_text):\n",
    "        input_text_word_count = len(input_text.split())\n",
    "        max_words = int(round(input_text_word_count * self.max_word_ratio))\n",
    "        input_args = {\"max_words\": max_words, \"input_text\": input_text}\n",
    "\n",
    "        response = self._get_response(**input_args)\n",
    "        output_text = response[\"choices\"][0][\"text\"].strip()\n",
    "        return output_text\n",
    "\n",
    "    def call_llm_with_res(self, input_text):\n",
    "        input_text_word_count = len(input_text.split())\n",
    "        max_words = int(round(input_text_word_count * self.max_word_ratio))\n",
    "        input_args = {\"max_words\": max_words, \"input_text\": input_text}\n",
    "\n",
    "        response = self._get_response(**input_args)\n",
    "        output_text = response[\"choices\"][0][\"text\"].strip()\n",
    "        return output_text, response\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:52:22.952416Z",
     "start_time": "2023-10-30T09:52:22.949226Z"
    }
   },
   "id": "8a0f86d747eb3b7f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# test_template = \"\"\"summarize the following text: {input_text}\"\"\"\n",
    "# \n",
    "# current_update_sum = OpenaiCompletionBase(\n",
    "#     model_name=\"text-davinci-003\",\n",
    "#     api_version=\"2023-05-15\",\n",
    "#     temperature=0.0,\n",
    "#     max_tokens=200,\n",
    "#     prompt_template=test_template\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:05:37.599446Z",
     "start_time": "2023-10-30T09:05:37.592488Z"
    }
   },
   "id": "1b127b2e20f50e11"
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "version_1_template = \"\"\"Summarize the key points of the text provided between the []. The summary MUST be concise and shorter than {max_words} words. Also, the output should be in the following structure: \n",
    "\\nTitle: <the title>\\n\n",
    "<the summary>.  \n",
    "----------------------\n",
    "The text to summarize: [{input_text}]\n",
    "\n",
    "The concise summary:\n",
    "\"\"\"\n",
    "\n",
    "version_1_sum = OpenaiCompletionWordLimit(\n",
    "    model_name=\"text-davinci-003\",\n",
    "    api_version=\"2023-05-15\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=200,\n",
    "    prompt_template=version_1_template,\n",
    "    max_word_ratio=0.6\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T11:56:35.949527Z",
     "start_time": "2023-10-30T11:56:35.944935Z"
    }
   },
   "id": "84ba6a760d33ad89"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "64044edc22a00825"
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [],
   "source": [
    "version_2_template = \"\"\"Using your deep linguistic understanding and knowledge, condense the essence of the provided content.\\n Retain the core ideas, crucial details, and significant context while omitting any extraneous information.\\n Please deliver a concise and coherent summary of the following text.\\n Respond only in string using less than {max_words} words.\\n The output MUST be in the following structure:\\nTitle: <the title>\\n<the summary>.\\n----------------------\n",
    "\\nThe text to summarize: {input_text}\\nThe summary:\\n\"\"\"\n",
    "\n",
    "version_2_sum = OpenaiCompletionWordLimit(\n",
    "    model_name=\"text-davinci-003\",\n",
    "    api_version=\"2023-05-15\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=512,\n",
    "    prompt_template=version_2_template,\n",
    "    max_word_ratio=0.75\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:30:51.048506Z",
     "start_time": "2023-10-30T12:30:51.045196Z"
    }
   },
   "id": "26e0fbd4e3beca5d"
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [],
   "source": [
    "version_3_template = \"\"\"Using your deep linguistic understanding and knowledge, condense the essence of the provided content. \\n        Retain the core ideas, crucial details, and significant context while omitting any extraneous information.\\n        Please deliver a concise and coherent summary of the following text of the user.\\n        Respond only in string.\\n        summarize this {input_text}\"\"\"\n",
    "\n",
    "version_3_sum = OpenaiCompletionBase(\n",
    "    model_name=\"text-davinci-003\",\n",
    "    api_version=\"2023-05-15\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=512,\n",
    "    prompt_template=version_3_template,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:41:43.135027Z",
     "start_time": "2023-10-30T12:41:43.130903Z"
    }
   },
   "id": "9176ecfdb9c964e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Apply on dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5541e3816e627a02"
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [],
   "source": [
    "model_name = \"version_3_summarizer\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:42:22.087019Z",
     "start_time": "2023-10-30T12:42:22.081159Z"
    }
   },
   "id": "28e60fd849cd9ffd"
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [],
   "source": [
    "# completion api\n",
    "data[model_name] = data['text'].apply(version_3_sum.call_llm)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:42:44.095343Z",
     "start_time": "2023-10-30T12:42:26.897304Z"
    }
   },
   "id": "742c39fd1cc398ab"
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Fire Breaks Out in Kentucky Industrial Park\n",
      "\n",
      "A mammoth fire broke out Friday morning in a Kentucky industrial park, with no reports of anyone injured or trapped. Firefighters sprayed water from the periphery of the affected buildings, and the cause of the fire is unknown. The park is large, with one of its warehouses being able to fit 34 football fields.\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[0].version_1_summarizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:42:53.212676Z",
     "start_time": "2023-10-30T12:42:53.208571Z"
    }
   },
   "id": "605781da9a9213a8"
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fire broke out Friday morning in a Kentucky industrial park, sending plumes of smoke over the area. No injuries or trapped people were reported. Firefighters sprayed water from the periphery of the affected buildings. The cause of the fire is unknown, and it had gone to at least four alarms. The Louisville Appliance Park is owned by General Electric and is \"revitalizing manufacturing in the United States,\" with one of its warehouses being large enough to fit 34 football fields.\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[0][model_name])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:42:56.153957Z",
     "start_time": "2023-10-30T12:42:56.149635Z"
    }
   },
   "id": "11a3a574fd61a970"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# data = data.drop('larium_devinci_summarizer',axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T11:04:26.183232Z",
     "start_time": "2023-10-30T11:04:26.177561Z"
    }
   },
   "id": "89e22294afe6e290"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### update config"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e322f26be407e4c"
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [],
   "source": [
    "conf_json.update({model_name:version_3_sum.get_config()})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:44:50.123481Z",
     "start_time": "2023-10-30T12:44:50.119804Z"
    }
   },
   "id": "e6aa6f512cd6a52d"
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [
    {
     "data": {
      "text/plain": "{'current_doc_summarizer': {'model_name': 'text-davinci-003',\n  'api_version': '2023-05-15',\n  'temperature': 0.0,\n  'max_tokens': 200,\n  'prompt_template': 'summarize the following text: {input_text}'},\n 'current_update_summarizer': {'model_name': 'text-davinci-003',\n  'api_version': '2023-05-15',\n  'temperature': 0.0,\n  'max_tokens': 200,\n  'prompt_template': 'summarize the following text: {input_text}'},\n 'version_1_summarizer': {'model_name': 'text-davinci-003',\n  'api_version': '2023-05-15',\n  'temperature': 0.0,\n  'max_tokens': 200,\n  'prompt_template': 'Summarize the key points of the text provided between the []. The summary MUST be concise and shorter than {max_words} words. Also, the output should be in the following structure: \\n\\nTitle: <the title>\\n\\n<the summary>.  \\n----------------------\\nThe text to summarize: [{input_text}]\\n\\nThe concise summary:\\n',\n  'max_word_ratio': 0.6},\n 'version_2_summarizer': {'model_name': 'text-davinci-003',\n  'api_version': '2023-05-15',\n  'temperature': 0.0,\n  'max_tokens': 512,\n  'prompt_template': 'Using your deep linguistic understanding and knowledge, condense the essence of the provided content.\\n Retain the core ideas, crucial details, and significant context while omitting any extraneous information.\\n Please deliver a concise and coherent summary of the following text.\\n Respond only in string using less than {max_words} words.\\n The output MUST be in the following structure:\\nTitle: <the title>\\n<the summary>.\\n----------------------\\n\\nThe text to summarize: {input_text}\\nThe summary:\\n',\n  'max_word_ratio': 0.75},\n 'version_3_summarizer': {'model_name': 'text-davinci-003',\n  'api_version': '2023-05-15',\n  'temperature': 0.0,\n  'max_tokens': 512,\n  'prompt_template': 'Using your deep linguistic understanding and knowledge, condense the essence of the provided content. \\n        Retain the core ideas, crucial details, and significant context while omitting any extraneous information.\\n        Please deliver a concise and coherent summary of the following text of the user.\\n        Respond only in string.\\n        summarize this {input_text}'}}"
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:44:54.103502Z",
     "start_time": "2023-10-30T12:44:54.097818Z"
    }
   },
   "id": "5645a1595be77389"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save data file and conf json"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74062288f866ad5a"
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [],
   "source": [
    "# save\n",
    "data.to_json(f\"{json_path}/{data_file_name}\", orient='index', indent=4, force_ascii=True)\n",
    "with open(f'{json_path}/{conf_file_name}', 'w', encoding='utf-8') as f:\n",
    "    json.dump(conf_json, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:45:00.073632Z",
     "start_time": "2023-10-30T12:45:00.070714Z"
    }
   },
   "id": "4238ff2bc932a4c9"
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:34:38.009912Z",
     "start_time": "2023-10-30T12:34:38.007043Z"
    }
   },
   "id": "1c1e45fa113514a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
